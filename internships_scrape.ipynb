{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python378jvsc74a57bd04dc2593f557a246ab4f3b8de594ca710e97ea68450a004a2e4feb043ce7ea460",
   "display_name": "Python 3.7.8 32-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "4dc2593f557a246ab4f3b8de594ca710e97ea68450a004a2e4feb043ce7ea460"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "WARNING: You are using pip version 21.0.1; however, version 21.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\python.exe -m pip install --upgrade pip' command.\n",
      "Requirement already satisfied: requests in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests) (1.26.4)\n",
      "WARNING: You are using pip version 21.0.1; however, version 21.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\python.exe -m pip install --upgrade pip' command.\n",
      "Requirement already satisfied: openpyxl in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (3.0.7)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "WARNING: You are using pip version 21.0.1; however, version 21.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "!pip install openpyxl\n",
    "import openpyxl\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from math import ceil\n",
    "from time import sleep \n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_main(link):\n",
    "    \n",
    "    \n",
    "    response = requests.get(link)\n",
    "    return(BeautifulSoup(response.text, 'lxml' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0       source                                           job_link\n",
       "0           0  internshala  https://internshala.com/internship/details/cov...\n",
       "1           1  internshala  https://internshala.com/internship/detail/data...\n",
       "2           2  internshala  https://internshala.com/internship/detail/soft...\n",
       "3           3  internshala  https://internshala.com/internship/detail/busi...\n",
       "4           4  internshala  https://internshala.com/internship/detail/mark..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>source</th>\n      <th>job_link</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>internshala</td>\n      <td>https://internshala.com/internship/details/cov...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>internshala</td>\n      <td>https://internshala.com/internship/detail/data...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>internshala</td>\n      <td>https://internshala.com/internship/detail/soft...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>internshala</td>\n      <td>https://internshala.com/internship/detail/busi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>internshala</td>\n      <td>https://internshala.com/internship/detail/mark...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "df = pd.read_csv(\"first_links.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Internship_Name=[]\n",
    "Internship_details_page_link=[]\n",
    "Internship_organization=[]\n",
    "Internship_organization_page_link=[]\n",
    "Location_of_internship=[]\n",
    "Start_date_of_internship=[]\n",
    "Duration=[]\n",
    "Stipend=[]\n",
    "Application_deadline=[] \n",
    "Number_of_applicants =[]\n",
    "Number_of_openings=[] \n",
    "\n",
    "for index,link in enumerate(df.job_link):\n",
    "    post = scrape_main(link)\n",
    "    if(post.find('div',attrs={'class':'heading_4_5 profile'}) == None):\n",
    "        continue\n",
    "    \n",
    "            \n",
    "    Internship_Name.append(post.find('div',attrs={'class':'heading_4_5 profile'}).span.text.strip())\n",
    "    Internship_details_page_link.append(link)\n",
    "    Internship_organization.append(post.find('div',attrs={'class':'heading_6 company_name'}).a.text.strip())\n",
    "    Internship_organization_page_link.append(\"https://internshala.com\"+post.find('div',attrs={'class':'heading_6 company_name'}).a.get('href'))\n",
    "\n",
    "    i=post.find('div',attrs={'class':'individual_internship_details individual_internship_internship'})\n",
    "    loc_names=i.find('div',attrs={'id':'location_names'})\n",
    "    Location_of_internship.append(loc_names.find('span').a.text.strip())\n",
    "\n",
    "    imp_fields = []\n",
    "    for i in post.find_all('div',{'class':'item_body'}):\n",
    "        imp_fields.append(i.get_text().strip())\n",
    "        \n",
    "    Start_date_of_internship.append(imp_fields[0].strip())\n",
    "    Duration.append(imp_fields[1].strip())   \n",
    "    Stipend.append(imp_fields[2].strip()) \n",
    "    Application_deadline.append(imp_fields[3].strip())\n",
    "    Number_of_applicants.append(post.find('div',{'class':'applications_message'}).text.strip())\n",
    "   \n",
    "\n",
    "\n",
    "    des=post.find('div',attrs={'class':'internship_details'})\n",
    "    for let in des.find_all('div',{'class':'text-container'}):\n",
    "        nop=let.get_text().strip()\n",
    "        if len(nop)<=3:\n",
    "            Number_of_openings.append(nop)\n",
    "            break\n",
    "    #sleep(500)   \n",
    "    \n",
    "results={}\n",
    "results['Internship Name']=Internship_Name\n",
    "results['Internship details page link']=Internship_details_page_link\n",
    "results['Internship organization']=Internship_organization\n",
    "results['Internship organization page link']=Internship_organization_page_link\n",
    "results['Location of internship']=Location_of_internship\n",
    "results['Start date of internship']=Start_date_of_internship\n",
    "results['Duration']=Duration\n",
    "results['Stipend']=Stipend\n",
    "results['Application deadline']=Application_deadline\n",
    "results['Number of applicants']=Number_of_applicants\n",
    "results['Number of openings']=Number_of_openings \n",
    "\n",
    "filename='C:/Users/aditya kumar/Desktop/PROJECTS/scraping/Scraping 3/internships.xlsx'\n",
    "df = pd.DataFrame.from_dict(results, orient='index')\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_excel(filename,index =False, encoding='utf-8')\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}